{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bfb7146",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import nltk\n",
    "import json\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM , Dense,GlobalAveragePooling1D,Flatten, Dropout , GRU\n",
    "from tensorflow.keras.models import Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.layers import Conv1D, MaxPool1D\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8005caae",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('intents.json', 'r') as json_data:\n",
    "    dataset = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4eb10172",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_json_dataset(dataset):\n",
    "  tags = []\n",
    "  inputs = []\n",
    "  responses={}\n",
    "  for intent in dataset['intents']:\n",
    "    responses[intent['intent']]=intent['responses']\n",
    "    for lines in intent['text']:\n",
    "      inputs.append(lines)\n",
    "      tags.append(intent['intent'])\n",
    "  return [tags, inputs, responses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "375db4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "[tags, inputs, responses] = processing_json_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fe28745",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame({\"inputs\":inputs,\n",
    "                     \"tags\":tags})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "042f5ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi</td>\n",
       "      <td>Greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi there</td>\n",
       "      <td>Greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hola</td>\n",
       "      <td>Greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hello</td>\n",
       "      <td>Greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hello there</td>\n",
       "      <td>Greeting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        inputs      tags\n",
       "0           Hi  Greeting\n",
       "1     Hi there  Greeting\n",
       "2         Hola  Greeting\n",
       "3        Hello  Greeting\n",
       "4  Hello there  Greeting"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7e06613",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc454431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>What causes mental illness?</td>\n",
       "      <td>MentalHealthFAQs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>What are the benefits of art therapy and creat...</td>\n",
       "      <td>MentalHealthFAQs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>How can I troubleshoot driver-related issues i...</td>\n",
       "      <td>UserFAQs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>What causes seasons on Earth?</td>\n",
       "      <td>ScienceQuery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>What is the capital of Indonesia?</td>\n",
       "      <td>CountriesKnowledgeInquiry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                inputs  \\\n",
       "160                        What causes mental illness?   \n",
       "153  What are the benefits of art therapy and creat...   \n",
       "445  How can I troubleshoot driver-related issues i...   \n",
       "179                      What causes seasons on Earth?   \n",
       "271                  What is the capital of Indonesia?   \n",
       "\n",
       "                          tags  \n",
       "160           MentalHealthFAQs  \n",
       "153           MentalHealthFAQs  \n",
       "445                   UserFAQs  \n",
       "179               ScienceQuery  \n",
       "271  CountriesKnowledgeInquiry  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79477f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "dataset['inputs'] = dataset['inputs'].apply(lambda sequence:\n",
    "                                            [ltrs.lower() for ltrs in sequence if ltrs not in string.punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4423ccf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>[w, h, a, t,  , c, a, u, s, e, s,  , m, e, n, ...</td>\n",
       "      <td>MentalHealthFAQs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>[w, h, a, t,  , a, r, e,  , t, h, e,  , b, e, ...</td>\n",
       "      <td>MentalHealthFAQs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>[h, o, w,  , c, a, n,  , i,  , t, r, o, u, b, ...</td>\n",
       "      <td>UserFAQs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>[w, h, a, t,  , c, a, u, s, e, s,  , s, e, a, ...</td>\n",
       "      <td>ScienceQuery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>[w, h, a, t,  , i, s,  , t, h, e,  , c, a, p, ...</td>\n",
       "      <td>CountriesKnowledgeInquiry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                inputs  \\\n",
       "160  [w, h, a, t,  , c, a, u, s, e, s,  , m, e, n, ...   \n",
       "153  [w, h, a, t,  , a, r, e,  , t, h, e,  , b, e, ...   \n",
       "445  [h, o, w,  , c, a, n,  , i,  , t, r, o, u, b, ...   \n",
       "179  [w, h, a, t,  , c, a, u, s, e, s,  , s, e, a, ...   \n",
       "271  [w, h, a, t,  , i, s,  , t, h, e,  , c, a, p, ...   \n",
       "\n",
       "                          tags  \n",
       "160           MentalHealthFAQs  \n",
       "153           MentalHealthFAQs  \n",
       "445                   UserFAQs  \n",
       "179               ScienceQuery  \n",
       "271  CountriesKnowledgeInquiry  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc1a8a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['inputs'] = dataset['inputs'].apply(lambda wrd: ''.join(wrd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8a2b85d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>what causes mental illness</td>\n",
       "      <td>MentalHealthFAQs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>what are the benefits of art therapy and creat...</td>\n",
       "      <td>MentalHealthFAQs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>how can i troubleshoot driverrelated issues in...</td>\n",
       "      <td>UserFAQs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>what causes seasons on earth</td>\n",
       "      <td>ScienceQuery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>what is the capital of indonesia</td>\n",
       "      <td>CountriesKnowledgeInquiry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                inputs  \\\n",
       "160                         what causes mental illness   \n",
       "153  what are the benefits of art therapy and creat...   \n",
       "445  how can i troubleshoot driverrelated issues in...   \n",
       "179                       what causes seasons on earth   \n",
       "271                   what is the capital of indonesia   \n",
       "\n",
       "                          tags  \n",
       "160           MentalHealthFAQs  \n",
       "153           MentalHealthFAQs  \n",
       "445                   UserFAQs  \n",
       "179               ScienceQuery  \n",
       "271  CountriesKnowledgeInquiry  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "287b104b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>how does the human brain work</td>\n",
       "      <td>ScienceQuery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>i am not talking to you</td>\n",
       "      <td>NotTalking2U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>who do you think i am</td>\n",
       "      <td>CurrentHumanQuery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>great thanks i am bella</td>\n",
       "      <td>CourtesyGreetingResponse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>how can i fix high cpu usage in windows 10</td>\n",
       "      <td>UserFAQs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         inputs                      tags\n",
       "169               how does the human brain work              ScienceQuery\n",
       "57                      i am not talking to you              NotTalking2U\n",
       "29                        who do you think i am         CurrentHumanQuery\n",
       "25                      great thanks i am bella  CourtesyGreetingResponse\n",
       "490  how can i fix high cpu usage in windows 10                  UserFAQs"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f47defab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=13200)\n",
    "tokenizer.fit_on_texts(dataset['inputs'])\n",
    "train = tokenizer.texts_to_sequences(dataset['inputs'])\n",
    "features = pad_sequences(train)\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(dataset['tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c686abdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91468911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "input_shape = features.shape[1]\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ec01780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 22)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a6729e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique words :  871\n",
      "output length:  28\n"
     ]
    }
   ],
   "source": [
    "vocabulary = len(tokenizer.word_index)\n",
    "print(\"number of unique words : \",vocabulary)\n",
    "output_length = le.classes_.shape[0]\n",
    "print(\"output length: \",output_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8311d698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'what': 2,\n",
       " 'i': 3,\n",
       " 'how': 4,\n",
       " 'of': 5,\n",
       " 'in': 6,\n",
       " 'can': 7,\n",
       " 'is': 8,\n",
       " 'and': 9,\n",
       " 'are': 10,\n",
       " 'do': 11,\n",
       " 'learning': 12,\n",
       " 'me': 13,\n",
       " 'you': 14,\n",
       " 'to': 15,\n",
       " 'for': 16,\n",
       " 'my': 17,\n",
       " 'tell': 18,\n",
       " 'windows': 19,\n",
       " 'a': 20,\n",
       " 'about': 21,\n",
       " 'it': 22,\n",
       " 'language': 23,\n",
       " 'with': 24,\n",
       " 'im': 25,\n",
       " 'machine': 26,\n",
       " 'mental': 27,\n",
       " 'capital': 28,\n",
       " 'official': 29,\n",
       " 'ai': 30,\n",
       " 'data': 31,\n",
       " 'unique': 32,\n",
       " 'explain': 33,\n",
       " 'whats': 34,\n",
       " 'some': 35,\n",
       " 'python': 36,\n",
       " 'deep': 37,\n",
       " 'concept': 38,\n",
       " 'model': 39,\n",
       " 'use': 40,\n",
       " 'health': 41,\n",
       " 'on': 42,\n",
       " 'neural': 43,\n",
       " 'models': 44,\n",
       " 'computer': 45,\n",
       " 'role': 46,\n",
       " 'networks': 47,\n",
       " 'thanks': 48,\n",
       " 'describe': 49,\n",
       " 'techniques': 50,\n",
       " 'system': 51,\n",
       " 'does': 52,\n",
       " 'work': 53,\n",
       " 'nlp': 54,\n",
       " 'name': 55,\n",
       " 'issues': 56,\n",
       " 'your': 57,\n",
       " 'this': 58,\n",
       " 'should': 59,\n",
       " 'working': 60,\n",
       " 'them': 61,\n",
       " 'error': 62,\n",
       " 'using': 63,\n",
       " 'natural': 64,\n",
       " 'not': 65,\n",
       " 'challenges': 66,\n",
       " 'am': 67,\n",
       " 'address': 68,\n",
       " 'or': 69,\n",
       " 'if': 70,\n",
       " 'performance': 71,\n",
       " 'tasks': 72,\n",
       " 'transfer': 73,\n",
       " 'strategies': 74,\n",
       " 'when': 75,\n",
       " 'training': 76,\n",
       " 'real': 77,\n",
       " 'image': 78,\n",
       " 'recognition': 79,\n",
       " 'resolve': 80,\n",
       " 'its': 81,\n",
       " 'effectively': 82,\n",
       " 'vision': 83,\n",
       " 'good': 84,\n",
       " 'process': 85,\n",
       " 'implement': 86,\n",
       " 'united': 87,\n",
       " 'recommendation': 88,\n",
       " 'problem': 89,\n",
       " 'handle': 90,\n",
       " 'call': 91,\n",
       " 'steps': 92,\n",
       " 'fix': 93,\n",
       " 'gossip': 94,\n",
       " 'projects': 95,\n",
       " 'detection': 96,\n",
       " 'talking': 97,\n",
       " 'who': 98,\n",
       " 'libraries': 99,\n",
       " 'illness': 100,\n",
       " 'troubleshoot': 101,\n",
       " 'facing': 102,\n",
       " 'up': 103,\n",
       " 'applications': 104,\n",
       " 'understanding': 105,\n",
       " 'improve': 106,\n",
       " 'user': 107,\n",
       " 'algorithms': 108,\n",
       " 'need': 109,\n",
       " 'well': 110,\n",
       " 'pythonbased': 111,\n",
       " 'text': 112,\n",
       " 'common': 113,\n",
       " 'between': 114,\n",
       " 'wont': 115,\n",
       " 'optimize': 116,\n",
       " 'see': 117,\n",
       " 'please': 118,\n",
       " 'gradient': 119,\n",
       " 'problems': 120,\n",
       " 'recover': 121,\n",
       " 'very': 122,\n",
       " 'bias': 123,\n",
       " 'missing': 124,\n",
       " 'used': 125,\n",
       " 'feature': 126,\n",
       " 'chatbot': 127,\n",
       " 'overfitting': 128,\n",
       " 'device': 129,\n",
       " 'anas': 130,\n",
       " 'reinforcement': 131,\n",
       " 'restore': 132,\n",
       " 'unsupervised': 133,\n",
       " 'analysis': 134,\n",
       " 'hello': 135,\n",
       " 'any': 136,\n",
       " 'impact': 137,\n",
       " 'from': 138,\n",
       " 'images': 139,\n",
       " 'recurrent': 140,\n",
       " 'rnns': 141,\n",
       " 'solutions': 142,\n",
       " 'handling': 143,\n",
       " 'datasets': 144,\n",
       " 'boot': 145,\n",
       " 'goodbye': 146,\n",
       " 'intelligence': 147,\n",
       " 'pretrained': 148,\n",
       " 'repair': 149,\n",
       " 'practices': 150,\n",
       " 'there': 151,\n",
       " 'object': 152,\n",
       " 'support': 153,\n",
       " 'know': 154,\n",
       " 'adam': 155,\n",
       " 'function': 156,\n",
       " 'thank': 157,\n",
       " 'classification': 158,\n",
       " 'safe': 159,\n",
       " 'issue': 160,\n",
       " 'processing': 161,\n",
       " 'doing': 162,\n",
       " 'network': 163,\n",
       " 'speed': 164,\n",
       " 'speech': 165,\n",
       " 'wasnt': 166,\n",
       " 'great': 167,\n",
       " 'bella': 168,\n",
       " 'custom': 169,\n",
       " 'want': 170,\n",
       " 'bye': 171,\n",
       " 'memory': 172,\n",
       " 'indonesia': 173,\n",
       " 'deleted': 174,\n",
       " 'malaysia': 175,\n",
       " 'thailand': 176,\n",
       " 'clever': 177,\n",
       " 'have': 178,\n",
       " 'selection': 179,\n",
       " 'provide': 180,\n",
       " 'their': 181,\n",
       " 'cells': 182,\n",
       " 'iran': 183,\n",
       " 'states': 184,\n",
       " 'updates': 185,\n",
       " 'write': 186,\n",
       " 'poetry': 187,\n",
       " 'hi': 188,\n",
       " 'struggling': 189,\n",
       " 'an': 190,\n",
       " 'building': 191,\n",
       " 'joke': 192,\n",
       " 'prevent': 193,\n",
       " 'importance': 194,\n",
       " 'egypt': 195,\n",
       " 'one': 196,\n",
       " 'manage': 197,\n",
       " 'enable': 198,\n",
       " 'china': 199,\n",
       " 'improving': 200,\n",
       " '10': 201,\n",
       " 'south': 202,\n",
       " 'korea': 203,\n",
       " 'kingdom': 204,\n",
       " 'wellbeing': 205,\n",
       " 'getting': 206,\n",
       " 'mean': 207,\n",
       " 'artificial': 208,\n",
       " 'get': 209,\n",
       " 'dealing': 210,\n",
       " 'effect': 211,\n",
       " 'fairness': 212,\n",
       " 'best': 213,\n",
       " 'principles': 214,\n",
       " 'mexico': 215,\n",
       " 'india': 216,\n",
       " 'potential': 217,\n",
       " 'japan': 218,\n",
       " 'task': 219,\n",
       " 'difference': 220,\n",
       " 'spain': 221,\n",
       " 'signs': 222,\n",
       " 'russia': 223,\n",
       " 'help': 224,\n",
       " 'update': 225,\n",
       " 'maintain': 226,\n",
       " 'ethics': 227,\n",
       " 'germany': 228,\n",
       " 'turkey': 229,\n",
       " 'ok': 230,\n",
       " 'word': 231,\n",
       " 'girl': 232,\n",
       " 'quiet': 233,\n",
       " 'slow': 234,\n",
       " 'time': 235,\n",
       " 'take': 236,\n",
       " 'accuracy': 237,\n",
       " 'italy': 238,\n",
       " 'stop': 239,\n",
       " 'france': 240,\n",
       " 'screen': 241,\n",
       " 'australia': 242,\n",
       " 'associated': 243,\n",
       " 'brazil': 244,\n",
       " 'bsod': 245,\n",
       " 'dimensionality': 246,\n",
       " 'content': 247,\n",
       " 'deploy': 248,\n",
       " 'argentina': 249,\n",
       " 'as': 250,\n",
       " 'build': 251,\n",
       " 'canada': 252,\n",
       " 'options': 253,\n",
       " 'pakistan': 254,\n",
       " 'causes': 255,\n",
       " 'benefits': 256,\n",
       " 'therapy': 257,\n",
       " 'mitigate': 258,\n",
       " 'files': 259,\n",
       " 'shut': 260,\n",
       " 'mechanisms': 261,\n",
       " 'mitigation': 262,\n",
       " 'deal': 263,\n",
       " 'dataset': 264,\n",
       " 'noisy': 265,\n",
       " 'methods': 266,\n",
       " 'information': 267,\n",
       " 'different': 268,\n",
       " 'installing': 269,\n",
       " 'start': 270,\n",
       " 'drift': 271,\n",
       " 'interpretability': 272,\n",
       " 'explainability': 273,\n",
       " 'by': 274,\n",
       " 'structure': 275,\n",
       " 'nlu': 276,\n",
       " 'preprocessing': 277,\n",
       " 'drive': 278,\n",
       " 'external': 279,\n",
       " 'lot': 280,\n",
       " 'reduce': 281,\n",
       " 'convolutional': 282,\n",
       " 'cnns': 283,\n",
       " 'sound': 284,\n",
       " 'waves': 285,\n",
       " 'considerations': 286,\n",
       " 'test': 287,\n",
       " 'contribute': 288,\n",
       " 'healthcare': 289,\n",
       " 'give': 290,\n",
       " 'remove': 291,\n",
       " 'while': 292,\n",
       " 'file': 293,\n",
       " 'encounter': 294,\n",
       " 'during': 295,\n",
       " 'achieve': 296,\n",
       " 'robustness': 297,\n",
       " 'no': 298,\n",
       " 'development': 299,\n",
       " 'specific': 300,\n",
       " 'greenhouse': 301,\n",
       " 'systems': 302,\n",
       " 'selfdriving': 303,\n",
       " 'personalized': 304,\n",
       " 'genetics': 305,\n",
       " 'generate': 306,\n",
       " 'risks': 307,\n",
       " 'ones': 308,\n",
       " 'overheating': 309,\n",
       " 'processes': 310,\n",
       " 'hya': 311,\n",
       " 'available': 312,\n",
       " 'connect': 313,\n",
       " 'wifi': 314,\n",
       " 'encountering': 315,\n",
       " 'convergence': 316,\n",
       " 'recognize': 317,\n",
       " 'experiencing': 318,\n",
       " 'anyone': 319,\n",
       " 'camera': 320,\n",
       " 'leverage': 321,\n",
       " 'properties': 322,\n",
       " 'employ': 323,\n",
       " 'deployment': 324,\n",
       " 'class': 325,\n",
       " 'imbalance': 326,\n",
       " 'saying': 327,\n",
       " 'pc': 328,\n",
       " 'automatic': 329,\n",
       " 'explainable': 330,\n",
       " 'xai': 331,\n",
       " 'imbalanced': 332,\n",
       " 'anomaly': 333,\n",
       " 'hyperparameter': 334,\n",
       " 'tuning': 335,\n",
       " 'right': 336,\n",
       " 'inheritance': 337,\n",
       " 'hope': 338,\n",
       " 'modeling': 339,\n",
       " 'embeddings': 340,\n",
       " 'intelligent': 341,\n",
       " 'interpret': 342,\n",
       " 'predictions': 343,\n",
       " 'be': 344,\n",
       " 'segmentation': 345,\n",
       " 'create': 346,\n",
       " 'loved': 347,\n",
       " 'understand': 348,\n",
       " 'suitable': 349,\n",
       " 'nuclear': 350,\n",
       " 'hola': 351,\n",
       " 'chemical': 352,\n",
       " 'robotics': 353,\n",
       " 'think': 354,\n",
       " 'profile': 355,\n",
       " 'check': 356,\n",
       " 'failure': 357,\n",
       " 'genious': 358,\n",
       " 'reducing': 359,\n",
       " 'engineering': 360,\n",
       " 'electromagnetic': 361,\n",
       " 'challenge': 362,\n",
       " 'enhance': 363,\n",
       " 'feeling': 364,\n",
       " 'accidentally': 365,\n",
       " 'disk': 366,\n",
       " 'errors': 367,\n",
       " 'graph': 368,\n",
       " 'vanishing': 369,\n",
       " 'tackle': 370,\n",
       " 'programs': 371,\n",
       " 'energy': 372,\n",
       " 'shutdown': 373,\n",
       " 'dna': 374,\n",
       " 'change': 375,\n",
       " 'desktop': 376,\n",
       " 'sleep': 377,\n",
       " 'stress': 378,\n",
       " 'important': 379,\n",
       " 'identify': 380,\n",
       " 'frameworks': 381,\n",
       " 'series': 382,\n",
       " 'vietnam': 383,\n",
       " 'augmentation': 384,\n",
       " 'usb': 385,\n",
       " 'generative': 386,\n",
       " 'adversarial': 387,\n",
       " 'gans': 388,\n",
       " 'theory': 389,\n",
       " 'gpus': 390,\n",
       " 'integrate': 391,\n",
       " 'software': 392,\n",
       " 'usage': 393,\n",
       " 'style': 394,\n",
       " 'periodic': 395,\n",
       " 'layers': 396,\n",
       " 'art': 397,\n",
       " 'creative': 398,\n",
       " 'expression': 399,\n",
       " 'promoting': 400,\n",
       " 'driverrelated': 401,\n",
       " 'seasons': 402,\n",
       " 'earth': 403,\n",
       " 'vanishingexploding': 404,\n",
       " 'attention': 405,\n",
       " 'improved': 406,\n",
       " 'cleaning': 407,\n",
       " 'types': 408,\n",
       " 'disorders': 409,\n",
       " 'characteristics': 410,\n",
       " 'mitochondria': 411,\n",
       " 'fever': 412,\n",
       " '0x80070643': 413,\n",
       " 'developing': 414,\n",
       " 'collaborative': 415,\n",
       " 'filtering': 416,\n",
       " 'cold': 417,\n",
       " 'streaming': 418,\n",
       " 'two': 419,\n",
       " 'lines': 420,\n",
       " 'head': 421,\n",
       " 'hurts': 422,\n",
       " 'atom': 423,\n",
       " 'intents': 424,\n",
       " 'format': 425,\n",
       " 'hard': 426,\n",
       " 'storage': 427,\n",
       " 'ive': 428,\n",
       " 'been': 429,\n",
       " 'coughing': 430,\n",
       " 'feelings': 431,\n",
       " 'loneliness': 432,\n",
       " 'isolation': 433,\n",
       " 'travel': 434,\n",
       " 'key': 435,\n",
       " 'implementing': 436,\n",
       " 'turing': 437,\n",
       " 'clustering': 438,\n",
       " 'keeps': 439,\n",
       " 'crashing': 440,\n",
       " 'got': 441,\n",
       " 'safety': 442,\n",
       " 'tips': 443,\n",
       " 'scaling': 444,\n",
       " 'denoising': 445,\n",
       " 'noise': 446,\n",
       " 'preserving': 447,\n",
       " 'details': 448,\n",
       " 'run': 449,\n",
       " 'sfc': 450,\n",
       " 'checker': 451,\n",
       " 'counseling': 452,\n",
       " 'menu': 453,\n",
       " 'cheering': 454,\n",
       " 'largescale': 455,\n",
       " 'displaying': 456,\n",
       " 'ntldr': 457,\n",
       " 'having': 458,\n",
       " '0xc00000e9': 459,\n",
       " 'jerk': 460,\n",
       " 'off': 461,\n",
       " 'set': 462,\n",
       " 'realistic': 463,\n",
       " 'goals': 464,\n",
       " 'generalizing': 465,\n",
       " 'new': 466,\n",
       " 'backpropagation': 467,\n",
       " 'bootable': 468,\n",
       " 'medical': 469,\n",
       " 'advice': 470,\n",
       " 'clean': 471,\n",
       " 'preprocess': 472,\n",
       " 'finetune': 473,\n",
       " 'shit': 474,\n",
       " 'doppler': 475,\n",
       " 'startup': 476,\n",
       " 'finetuning': 477,\n",
       " 'cars': 478,\n",
       " 'cv': 479,\n",
       " 'medicine': 480,\n",
       " 'mendelian': 481,\n",
       " 'generation': 482,\n",
       " 'coherent': 483,\n",
       " 'contextaware': 484,\n",
       " 'tracking': 485,\n",
       " 'neglecting': 486,\n",
       " 'gaming': 487,\n",
       " 'manager': 488,\n",
       " 'supervised': 489,\n",
       " 'online': 490,\n",
       " 'resources': 491,\n",
       " 'hotlines': 492,\n",
       " 'immediate': 493,\n",
       " 'game': 494,\n",
       " 'playing': 495,\n",
       " 'descent': 496,\n",
       " 'gradientbased': 497,\n",
       " 'buoyancy': 498,\n",
       " 'fluids': 499,\n",
       " 'depression': 500,\n",
       " 'someone': 501,\n",
       " 'seeking': 502,\n",
       " 'professional': 503,\n",
       " 'concerns': 504,\n",
       " 'exploratory': 505,\n",
       " 'stomach': 506,\n",
       " 'aches': 507,\n",
       " '0x80070422': 508,\n",
       " 'acids': 509,\n",
       " 'bases': 510,\n",
       " 'reset': 511,\n",
       " 'password': 512,\n",
       " 'forget': 513,\n",
       " 'ecosystems': 514,\n",
       " 'balance': 515,\n",
       " 'decision': 516,\n",
       " 'trees': 517,\n",
       " 'immune': 518,\n",
       " 'malware': 519,\n",
       " 'viruses': 520,\n",
       " 'computational': 521,\n",
       " 'cost': 522,\n",
       " 'electric': 523,\n",
       " 'circuits': 524,\n",
       " 'stuck': 525,\n",
       " 'preparing': 526,\n",
       " 'loop': 527,\n",
       " 'escape': 528,\n",
       " 'later': 529,\n",
       " 'mode': 530,\n",
       " 'enter': 531,\n",
       " 'hormones': 532,\n",
       " 'endocrine': 533,\n",
       " '0x8024a105': 534,\n",
       " 'struggles': 535,\n",
       " 'outofvocabulary': 536,\n",
       " 'words': 537,\n",
       " 'keyboard': 538,\n",
       " 'mouse': 539,\n",
       " 'people': 540,\n",
       " 'mindfulness': 541,\n",
       " 'choose': 542,\n",
       " 'algorithm': 543,\n",
       " 'stages': 544,\n",
       " 'mitosis': 545,\n",
       " 'cell': 546,\n",
       " 'division': 547,\n",
       " 'networkbased': 548,\n",
       " 'relationship': 549,\n",
       " 'term': 550,\n",
       " 'labeling': 551,\n",
       " 'bayesian': 552,\n",
       " 'probabilistic': 553,\n",
       " 'semantic': 554,\n",
       " 'blackbox': 555,\n",
       " 'sentiment': 556,\n",
       " 'affect': 557,\n",
       " 'pose': 558,\n",
       " 'estimation': 559,\n",
       " 'warning': 560,\n",
       " 'selfattention': 561,\n",
       " 'transformer': 562,\n",
       " 'applied': 563,\n",
       " 'plants': 564,\n",
       " 'adapt': 565,\n",
       " 'environments': 566,\n",
       " 'medication': 567,\n",
       " 'divide': 568,\n",
       " 'deteriorates': 569,\n",
       " 'over': 570,\n",
       " 'monitoring': 571,\n",
       " 'maintenance': 572,\n",
       " 'dialects': 573,\n",
       " 'accents': 574,\n",
       " 'large': 575,\n",
       " 'efficient': 576,\n",
       " 'loading': 577,\n",
       " 'precautions': 578,\n",
       " 'stabilize': 579,\n",
       " 'classifier': 580,\n",
       " 'supportive': 581,\n",
       " 'environment': 582,\n",
       " 'discussing': 583,\n",
       " 'radioactive': 584,\n",
       " 'decay': 585,\n",
       " 'could': 586,\n",
       " 'developed': 587,\n",
       " 'visualize': 588,\n",
       " 'vector': 589,\n",
       " 'machines': 590,\n",
       " 'svms': 591,\n",
       " 'enzymes': 592,\n",
       " 'biological': 593,\n",
       " 'fission': 594,\n",
       " 'flickering': 595,\n",
       " 'opportunities': 596,\n",
       " 'environmental': 597,\n",
       " 'sustainability': 598,\n",
       " 'bonds': 599,\n",
       " 'form': 600,\n",
       " 'break': 601,\n",
       " 'future': 602,\n",
       " 'code': 603,\n",
       " 'troubleshooter': 604,\n",
       " 'kernel': 605,\n",
       " 'security': 606,\n",
       " 'finance': 607,\n",
       " 'investment': 608,\n",
       " 'industry': 609,\n",
       " 'drugs': 610,\n",
       " 'multimodal': 611,\n",
       " 'involving': 612,\n",
       " 'both': 613,\n",
       " 'joint': 614,\n",
       " 'autonomous': 615,\n",
       " 'apply': 616,\n",
       " 'black': 617,\n",
       " 'hole': 618,\n",
       " 'highdimensional': 619,\n",
       " 'twat': 620,\n",
       " 'running': 621,\n",
       " 'reduction': 622,\n",
       " 'production': 623,\n",
       " 'spectrum': 624,\n",
       " 'curse': 625,\n",
       " 'bored': 626,\n",
       " 'outofdistribution': 627,\n",
       " 'lost': 628,\n",
       " 'unsaved': 629,\n",
       " 'documents': 630,\n",
       " 'sometimes': 631,\n",
       " 'misses': 632,\n",
       " 'objects': 633,\n",
       " 'was': 634,\n",
       " 'disable': 635,\n",
       " 'operating': 636,\n",
       " 'communicating': 637,\n",
       " 'nutrition': 638,\n",
       " 'physical': 639,\n",
       " 'activity': 640,\n",
       " 'corrupted': 641,\n",
       " 'earthquakes': 642,\n",
       " 'occur': 643,\n",
       " 'fraud': 644,\n",
       " 'recycle': 645,\n",
       " 'bin': 646,\n",
       " 'icon': 647,\n",
       " 'jokes': 648,\n",
       " 'sparsity': 649,\n",
       " 'more': 650,\n",
       " 'chkdsk': 651,\n",
       " 'analytics': 652,\n",
       " 'select': 653,\n",
       " 'evaluation': 654,\n",
       " 'metrics': 655,\n",
       " 'regression': 656,\n",
       " 'neurotransmitters': 657,\n",
       " 'nervous': 658,\n",
       " 'install': 659,\n",
       " 'agents': 660,\n",
       " 'overcome': 661,\n",
       " 'blue': 662,\n",
       " 'death': 663,\n",
       " 'unwanted': 664,\n",
       " 'starting': 665,\n",
       " 'at': 666,\n",
       " 'stars': 667,\n",
       " 'produce': 668,\n",
       " 'hyperparameters': 669,\n",
       " 'inaccessible': 670,\n",
       " 'thats': 671,\n",
       " 'helpful': 672,\n",
       " 'search': 673,\n",
       " 'expected': 674,\n",
       " 'down': 675,\n",
       " 'meant': 676,\n",
       " 'ethical': 677,\n",
       " 'wallpaper': 678,\n",
       " 'links': 679,\n",
       " 'quality': 680,\n",
       " 'crossvalidation': 681,\n",
       " 'train': 682,\n",
       " 'recommendations': 683,\n",
       " 'managing': 684,\n",
       " 'symptoms': 685,\n",
       " 'posttraumatic': 686,\n",
       " 'disorder': 687,\n",
       " 'ptsd': 688,\n",
       " 'circulatory': 689,\n",
       " 'fossils': 690,\n",
       " 'formed': 691,\n",
       " 'anomalies': 692,\n",
       " 'outliers': 693,\n",
       " 'hear': 694,\n",
       " 'underfitting': 695,\n",
       " 'tides': 696,\n",
       " 'today': 697,\n",
       " 'make': 698,\n",
       " 'laugh': 699,\n",
       " 'popular': 700,\n",
       " 'forecasting': 701,\n",
       " 'leaks': 702,\n",
       " 'detect': 703,\n",
       " 'photosynthesis': 704,\n",
       " 'perform': 705,\n",
       " 'temporal': 706,\n",
       " 'dependencies': 707,\n",
       " 'sequencetosequence': 708,\n",
       " 'such': 709,\n",
       " 'translation': 710,\n",
       " 'wake': 711,\n",
       " 'optimizing': 712,\n",
       " 'treatment': 713,\n",
       " 'ensemble': 714,\n",
       " 'coping': 715,\n",
       " 'anxiety': 716,\n",
       " 'panic': 717,\n",
       " 'attacks': 718,\n",
       " 'effects': 719,\n",
       " 'substance': 720,\n",
       " 'abuse': 721,\n",
       " 'heisenberg': 722,\n",
       " 'uncertainty': 723,\n",
       " 'principle': 724,\n",
       " 'video': 725,\n",
       " 'captioning': 726,\n",
       " 'enough': 727,\n",
       " 'laptop': 728,\n",
       " 'monitor': 729,\n",
       " 'avoid': 730,\n",
       " 'sick': 731,\n",
       " 'cuda': 732,\n",
       " 'out': 733,\n",
       " 'decisionmaking': 734,\n",
       " 'adios': 735,\n",
       " 'requires': 736,\n",
       " 'labeled': 737,\n",
       " 'web': 738,\n",
       " 'service': 739,\n",
       " 'serving': 740,\n",
       " 'compare': 741,\n",
       " 'plate': 742,\n",
       " 'tectonics': 743,\n",
       " 'social': 744,\n",
       " 'community': 745,\n",
       " 'play': 746,\n",
       " 'maintaining': 747,\n",
       " 'stigmas': 748,\n",
       " 'we': 749,\n",
       " 'combat': 750,\n",
       " 'stay': 751,\n",
       " 'restart': 752,\n",
       " 'customize': 753,\n",
       " 'appearance': 754,\n",
       " 'settings': 755,\n",
       " 'why': 756,\n",
       " 'genetic': 757,\n",
       " 'driver': 758,\n",
       " 'power': 759,\n",
       " 'state': 760,\n",
       " 'languages': 761,\n",
       " 'recognized': 762,\n",
       " 'unwell': 763,\n",
       " 'field': 764,\n",
       " 'education': 765,\n",
       " 'elearning': 766,\n",
       " 'speaking': 767,\n",
       " 'latency': 768,\n",
       " 'aibased': 769,\n",
       " 'virtual': 770,\n",
       " 'assistants': 771,\n",
       " 'like': 772,\n",
       " 'siri': 773,\n",
       " 'alexa': 774,\n",
       " 'relativity': 775,\n",
       " 'resilience': 776,\n",
       " 'face': 777,\n",
       " 'lifes': 778,\n",
       " 'setbacks': 779,\n",
       " 'parallelize': 780,\n",
       " 'multiple': 781,\n",
       " 'into': 782,\n",
       " 'mobile': 783,\n",
       " 'shhh': 784,\n",
       " 'advantages': 785,\n",
       " 'vehicles': 786,\n",
       " 'disaster': 787,\n",
       " 'prediction': 788,\n",
       " 'response': 789,\n",
       " 'preventing': 790,\n",
       " 'built': 791,\n",
       " 'gas': 792,\n",
       " 'climate': 793,\n",
       " 'dumb': 794,\n",
       " 'resolution': 795,\n",
       " 'incorrect': 796,\n",
       " 'adjust': 797,\n",
       " 'evolution': 798,\n",
       " 'named': 799,\n",
       " 'entity': 800,\n",
       " 'ner': 801,\n",
       " 'fusion': 802,\n",
       " 'emotional': 803,\n",
       " 'significance': 804,\n",
       " 'comprendo': 805,\n",
       " 'backup': 806,\n",
       " 'synthesis': 807,\n",
       " 'selfcare': 808,\n",
       " 'that': 809,\n",
       " 'better': 810,\n",
       " 'reactions': 811,\n",
       " 'they': 812,\n",
       " 'balanced': 813,\n",
       " '0x80070570': 814,\n",
       " 'gpu': 815,\n",
       " 'friends': 816,\n",
       " 'purpose': 817,\n",
       " 'cleanup': 818,\n",
       " 'osmosis': 819,\n",
       " 'medications': 820,\n",
       " 'uninstall': 821,\n",
       " 'but': 822,\n",
       " 'theyre': 823,\n",
       " 'performing': 824,\n",
       " 'narrow': 825,\n",
       " 'ani': 826,\n",
       " 'general': 827,\n",
       " 'agi': 828,\n",
       " 'capabilities': 829,\n",
       " 'backend': 830,\n",
       " 'atp': 831,\n",
       " 'cellular': 832,\n",
       " 'chatbots': 833,\n",
       " 'meaningful': 834,\n",
       " 'responses': 835,\n",
       " 'friend': 836,\n",
       " 'refine': 837,\n",
       " 'boundaries': 838,\n",
       " 'gptstyle': 839,\n",
       " 'selfcompassion': 840,\n",
       " 'practice': 841,\n",
       " 'habits': 842,\n",
       " 'workplace': 843,\n",
       " 'limited': 844,\n",
       " 'access': 845,\n",
       " 'water': 846,\n",
       " 'cycle': 847,\n",
       " 'changing': 848,\n",
       " 'windowsold': 849,\n",
       " 'delete': 850,\n",
       " '0x80004005': 851,\n",
       " 'extracting': 852,\n",
       " 'compressed': 853,\n",
       " 'related': 854,\n",
       " 'regularize': 855,\n",
       " 'big': 856,\n",
       " 'bang': 857,\n",
       " 'sense': 858,\n",
       " 'disambiguation': 859,\n",
       " 'trends': 860,\n",
       " 'table': 861,\n",
       " 'light': 862,\n",
       " 'laws': 863,\n",
       " 'thermodynamics': 864,\n",
       " 'hubble': 865,\n",
       " 'space': 866,\n",
       " 'telescope': 867,\n",
       " 'human': 868,\n",
       " 'brain': 869,\n",
       " 'high': 870,\n",
       " 'cpu': 871}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e8aea14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building RNN Model\n",
    "vocabulary = 871  # Approximate number of unique words in dataset\n",
    "output_length = 28 # Define the output length (number of classes or words)\n",
    "m = Sequential()\n",
    "m.add(Input(shape=(features.shape[1])))\n",
    "m.add(Embedding(vocabulary + 1,200))\n",
    "m.add(Conv1D(filters=32, kernel_size=5, activation=\"relu\", kernel_initializer=tf.keras.initializers.GlorotNormal(),bias_regularizer=tf.keras.regularizers.L2(0.0001), kernel_regularizer=tf.keras.regularizers.L2(0.0001), activity_regularizer = tf.keras.regularizers.L2(0.0001))) \n",
    "m.add(Dropout(0.3))\n",
    "m.add(LSTM(64, dropout=0.3,return_sequences=True))\n",
    "m.add(LSTM(32, dropout=0.3,return_sequences=False))\n",
    "m.add(Dense(256,activation=\"relu\", activity_regularizer = tf.keras.regularizers.L2(0.0001))) \n",
    "m.add(Dropout(0.6))\n",
    "m.add(Dense(output_length, activation=\"softmax\", activity_regularizer = tf.keras.regularizers.L2(0.0001)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "732dd7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import scipy\n",
    "import requests\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cf3e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_folder = \"C:\\\\Users\\Kaleem\\\\\"\n",
    "\n",
    "\n",
    "url = \"https://nlp.stanford.edu/data/glove.6B.zip\"\n",
    "file_name = \"glove.6B.zip\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    with open(file_name, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "    print(\"File downloaded successfully.\")\n",
    "else:\n",
    "    print(\"Failed to download the file. Status code:\", response.status_code)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ae7031f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip the downloaded file to the specified destination folder\n",
    "with zipfile.ZipFile(file_name, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(destination_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b70aea5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "glove_dir = \"glove.6B.200d.txt\"\n",
    "embeddings_index = {}\n",
    "file_ = open(glove_dir, encoding='utf-8')  # Specify the encoding as UTF-8\n",
    "for line in file_:\n",
    "    arr = line.split()\n",
    "    single_word = arr[0]\n",
    "    w = np.asarray(arr[1:], dtype='float32')\n",
    "    embeddings_index[single_word] = w\n",
    "file_.close()\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ef91c475",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = vocabulary + 1\n",
    "word_index = tokenizer.word_index\n",
    "embedding_matrix = np.zeros((max_words,200)).astype(object)\n",
    "for word , i in word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dc312ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.layers[0].set_weights([embedding_matrix])\n",
    "m.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "20b85cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.compile(loss=\"sparse_categorical_crossentropy\",optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6718e524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 22, 200)           174400    \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 18, 32)            32032     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 18, 32)            0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 18, 64)            24832     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 32)                12416     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               8448      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 28)                7196      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 259324 (1012.98 KB)\n",
      "Trainable params: 84924 (331.73 KB)\n",
      "Non-trainable params: 174400 (681.25 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "66a038cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard, EarlyStopping\n",
    "earlyStopping = EarlyStopping(monitor = 'loss', patience = 400, mode = 'min', restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5a4b8da5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.0743 - accuracy: 0.9840\n",
      "Epoch 2/1000\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.0789 - accuracy: 0.9840\n",
      "Epoch 3/1000\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.0719 - accuracy: 0.9900\n",
      "Epoch 4/1000\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.0739 - accuracy: 0.9860\n",
      "Epoch 5/1000\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.0677 - accuracy: 0.9840\n",
      "Epoch 6/1000\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 0.0563 - accuracy: 0.9900\n",
      "Epoch 7/1000\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.0766 - accuracy: 0.9820\n",
      "Epoch 8/1000\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 0.0566 - accuracy: 0.9900\n",
      "Epoch 9/1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5844\\3716067307.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory_training\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m \u001b[0mearlyStopping\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1740\u001b[0m                         ):\n\u001b[0;32m   1741\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1742\u001b[1;33m                             \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1743\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1744\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    823\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 825\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    826\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    855\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    856\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 857\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    858\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    146\u001b[0m       (concrete_function,\n\u001b[0;32m    147\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[1;33m     return concrete_function._call_flat(\n\u001b[0m\u001b[0;32m    149\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1347\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1348\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1349\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_call_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1350\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\context.py\u001b[0m in \u001b[0;36mcall_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1456\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1457\u001b[1;33m       outputs = execute.execute(\n\u001b[0m\u001b[0;32m   1458\u001b[0m           \u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1459\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history_training = m.fit(features,labels,epochs=1000, batch_size=64, callbacks=[ earlyStopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3e061469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 2s 24ms/step - loss: 0.0356 - accuracy: 0.9980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03561866283416748, 0.9980000257492065]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate(features, labels, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "49281b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing our chatbot\n",
    "import random\n",
    "def generate_answer(query):\n",
    "  texts = []\n",
    "  pred_input = query\n",
    "  pred_input = [letters.lower() for letters in pred_input if letters not in string.punctuation]\n",
    "  pred_input = ''.join(pred_input)\n",
    "  texts.append(pred_input)\n",
    "  pred_input = tokenizer.texts_to_sequences(texts)\n",
    "  pred_input = np.array(pred_input).reshape(-1)\n",
    "  pred_input = pad_sequences([pred_input],input_shape)\n",
    "  output = m.predict(pred_input)\n",
    "  output = output.argmax()\n",
    "  response_tag = le.inverse_transform([output])[0]\n",
    "  return random.choice(responses[response_tag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "25ce1d95",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you: hello\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Hi! I'm here to assist you. What's on your mind?\n",
      "you: tell me May Name\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Your name is Anas, how can I help you?\n",
      "you: shit\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "I am sorry Boss\n",
      "you: what is your real name?\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "My name is M.A.R.C, short for Multifunctional AI Response Companion\n",
      "you: tell me a gossip\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "John said he follow a saying to get a friend I must be a friend.\n",
      "you: write some poetry,\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "Footprints in the sand, a journey shared, Memories created, for those who cared\n",
      "you: YO ARE VERY INTELLIGENT\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Thank you, I was trained that way\n",
      "you: i feel sick today\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "I see. It's important to address your health concerns. What symptoms are you experiencing?\n",
      "you: cough\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "I read you loud and clear!\n",
      "you: can you give me sAfety Tips?\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Of course, taking precautions is important. In general, it's essential to maintain good hygiene, wash your hands regularly, and avoid close contact with sick individuals. If you have specific symptoms, consult a healthcare professional for guidance.\n"
     ]
    }
   ],
   "source": [
    "list_que = [\"hello\", \"tell me May Name\",\"shit\",\"what is your real name?\",\"tell me a gossip\",\n",
    "            \"write some poetry,\",\"YO ARE VERY INTELLIGENT\",\"i feel sick today\",\"cough\",\"can you give me sAfety Tips?\",]\n",
    "for i in list_que:\n",
    "  print(\"you: {}\".format(i))\n",
    "  res_tag = generate_answer(i)\n",
    "  print(res_tag)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d53c1bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyyaml in c:\\users\\kaleem\\anaconda3\\lib\\site-packages (6.0)\n",
      "Requirement already satisfied: h5py in c:\\users\\kaleem\\anaconda3\\lib\\site-packages (3.7.0)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\kaleem\\anaconda3\\lib\\site-packages (from h5py) (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "#saving the model\n",
    "!pip install pyyaml h5py\n",
    "\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "76fdf142",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.save(\"Marc_chatbot.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c75d82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
